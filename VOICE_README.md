# ğŸ¤ Sistema de Reconocimiento de Voz con IA Local (Ollama)

## ğŸ‰ Â¡ImplementaciÃ³n Completa!

Se ha creado un sistema completo de reconocimiento de voz que permite registrar ingresos mediante comandos de voz, utilizando **Ollama** para procesamiento inteligente con IA local.

---

## ğŸ“¦ Archivos Creados

### Frontend (React Native/Expo):
```
sysapp/
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ VoiceRecognition.tsx        # Componente base de reconocimiento de voz
â”‚   â”œâ”€â”€ VoiceIngresoModal.tsx       # Modal completo para registrar ingresos por voz
â”‚   â””â”€â”€ ModalSuccess.tsx            # Modal de Ã©xito rediseÃ±ado (mejorado)
â”œâ”€â”€ hooks/
â”‚   â””â”€â”€ useVoiceToIncome.ts         # Hook para integraciÃ³n con backend/Ollama
â””â”€â”€ VOICE_INTEGRATION_SETUP.md      # GuÃ­a de configuraciÃ³n detallada
```

### Backend (Node.js):
```
server/
â”œâ”€â”€ controllers/
â”‚   â””â”€â”€ Voice/
â”‚       â””â”€â”€ voiceController.js      # Controlador con lÃ³gica de Ollama
â””â”€â”€ routes/
    â””â”€â”€ Voice/
        â””â”€â”€ voiceRoutes.js          # Rutas API de reconocimiento de voz
```

---

## ğŸš€ Setup RÃ¡pido (3 pasos)

### 1ï¸âƒ£ Instalar Dependencias

**Frontend:**
```bash
cd c:\SIS_VENTAS_NEXT\migracion_app_cliente\sysapp
npm install @react-native-voice/voice expo-linear-gradient
```

**Backend:**
```bash
cd c:\SIS_VENTAS_NEXT\migracion_app_cliente\server
npm install axios
```

### 2ï¸âƒ£ Configurar Ollama

**Instalar Ollama (Windows):**
```bash
# OpciÃ³n 1: Winget
winget install Ollama.Ollama

# OpciÃ³n 2: Descargar desde https://ollama.com/download
```

**Iniciar Ollama:**
```bash
# Terminal 1: Iniciar servidor
ollama serve

# Terminal 2: Descargar modelo
ollama pull llama3.2
```

### 3ï¸âƒ£ Configurar Backend

**Editar `server/server.js`:**

Agregar el import (lÃ­nea 34, despuÃ©s de `emailConfigRoutes`):
```javascript
import voiceRoutes from './routes/Voice/voiceRoutes.js';
```

Registrar la ruta (lÃ­nea 103, despuÃ©s de otros `app.use`):
```javascript
app.use('/api/voice', voiceRoutes);
```

**Editar `server/.env`:**
```env
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2
```

---

## ğŸ’» Uso del Sistema

### OpciÃ³n 1: Modal Completo (Recomendado)

```tsx
import { useState } from 'react';
import { Pressable, Text } from 'react-native';
import VoiceIngresoModal from './components/VoiceIngresoModal';

function MiComponente() {
  const [showVoiceModal, setShowVoiceModal] = useState(false);

  const handleIngresoRegistrado = (ingreso) => {
    console.log("Ingreso registrado:", ingreso);
    // AquÃ­ puedes guardar en tu base de datos
    // await registrarIngreso(ingreso);
  };

  return (
    <>
      <Pressable onPress={() => setShowVoiceModal(true)}>
        <Text>ğŸ¤ Registrar por Voz</Text>
      </Pressable>

      <VoiceIngresoModal
        isOpen={showVoiceModal}
        onClose={() => setShowVoiceModal(false)}
        onIngresoRegistrado={handleIngresoRegistrado}
      />
    </>
  );
}
```

### OpciÃ³n 2: Componente Individual

```tsx
import VoiceRecognition from './components/VoiceRecognition';
import { useVoiceToIncome } from './hooks/useVoiceToIncome';

function MiComponente() {
  const { parseVoiceToIncome, isProcessing } = useVoiceToIncome();

  const handleVoiceResult = async (text: string) => {
    const parsedData = await parseVoiceToIncome(text);
    if (parsedData) {
      console.log("Datos:", parsedData);
      // Usar los datos extraÃ­dos
    }
  };

  return (
    <VoiceRecognition
      onResult={handleVoiceResult}
      onError={(error) => console.error(error)}
      enableProcessing={isProcessing}
    />
  );
}
```

---

## ğŸ¯ Ejemplos de Comandos de Voz

El sistema entiende frases naturales como:

âœ… **"Registrar un ingreso de 150 dÃ³lares por venta de equipos"**
- Monto: 150
- Concepto: "Venta de equipos"
- Tipo: INGRESO_VENTA

âœ… **"Ingreso de 50 pesos por servicio tÃ©cnico"**
- Monto: 50
- Concepto: "Servicio tÃ©cnico"
- Tipo: INGRESO_SERVICIO

âœ… **"Anotar 75 dÃ³lares por concepto de reparaciÃ³n"**
- Monto: 75
- Concepto: "ReparaciÃ³n"
- Tipo: INGRESO_SERVICIO

âœ… **"Venta de productos por 200 dÃ³lares"**
- Monto: 200
- Concepto: "Venta de productos"
- Tipo: INGRESO_VENTA

---

## ğŸ”§ API Endpoints

### 1. Verificar salud de Ollama
```bash
GET /api/voice/health
```

**Respuesta:**
```json
{
  "status": "ok",
  "message": "Ollama estÃ¡ disponible",
  "models": ["llama3.2", "mistral"]
}
```

### 2. Parsear comando de voz
```bash
POST /api/voice/parse-income
Headers: Authorization: Bearer {token}
Body: {
  "text": "Registrar un ingreso de 150 dÃ³lares por venta"
}
```

**Respuesta:**
```json
{
  "monto": 150,
  "concepto": "Venta",
  "tipo_movimiento": "INGRESO_VENTA",
  "observaciones": "Registrar un ingreso de 150 dÃ³lares por venta",
  "confidence": 95,
  "fecha": "2025-11-21T23:30:00.000Z"
}
```

---

## ğŸ¨ CaracterÃ­sticas del Sistema

### Componente VoiceRecognition:
- âœ¨ **Animaciones profesionales** con ondas expansivas
- ğŸ¤ **BotÃ³n de micrÃ³fono** con gradiente y efecto pulso
- ğŸ”´ **Indicador visual** cuando estÃ¡ escuchando
- ğŸ“ **Muestra texto en tiempo real** mientras hablas
- âš¡ **Feedback de procesamiento** con spinner
- ğŸ¯ **Manejo de errores** con mensajes claros

### VoiceIngresoModal:
- ğŸ“Š **Vista previa de datos** extraÃ­dos antes de confirmar
- âœ… **Nivel de confianza** visual con barra de progreso
- ğŸ¨ **DiseÃ±o moderno** con gradientes y sombras
- ğŸ“± **Responsive** para diferentes tamaÃ±os de pantalla
- ğŸ”” **Modal de Ã©xito** con auto-cierre
- ğŸ’¡ **Instrucciones integradas** con ejemplos

### Backend con Ollama:
- ğŸ¤– **IA local** (sin dependencia de servicios cloud)
- ğŸ”„ **Fallback parser** si Ollama no estÃ¡ disponible
- âœ… **ValidaciÃ³n automÃ¡tica** de datos extraÃ­dos
- ğŸ“Š **Nivel de confianza** del anÃ¡lisis (0-100%)
- ğŸŒ **Soporte multiidioma** (configurable)
- âš¡ **Respuesta rÃ¡pida** (< 2 segundos)

---

## ğŸ› Troubleshooting

### âŒ "Ollama no estÃ¡ disponible"

**SoluciÃ³n:**
```bash
# Iniciar Ollama
ollama serve

# Verificar que estÃ¡ corriendo
curl http://localhost:11434/api/tags
```

### âŒ "Model not found: llama3.2"

**SoluciÃ³n:**
```bash
# Descargar el modelo
ollama pull llama3.2

# Verificar modelos instalados
ollama list
```

### âŒ Error de permisos de micrÃ³fono

**Android:**
```xml
<!-- android/app/src/main/AndroidManifest.xml -->
<uses-permission android:name="android.permission.RECORD_AUDIO" />
```

**iOS:**
```xml
<!-- ios/YourApp/Info.plist -->
<key>NSMicrophoneUsageDescription</key>
<string>Para reconocimiento de voz</string>
<key>NSSpeechRecognitionUsageDescription</key>
<string>Para registrar ingresos por voz</string>
```

Luego reinstalar:
```bash
# Android
npx expo run:android

# iOS
npx expo run:ios
```

### âŒ "Cannot find module '@react-native-voice/voice'"

**SoluciÃ³n:**
```bash
npm install @react-native-voice/voice
npx expo prebuild
```

### âŒ Backend no responde

**Verificar servidor:**
```bash
cd c:\SIS_VENTAS_NEXT\migracion_app_cliente\server
npm run dev
```

**Verificar logs:**
```bash
# Buscar errores en la consola del servidor
# DeberÃ­a mostrar: "Server running on port 3000"
```

---

## ğŸ” Seguridad

- âœ… Requiere autenticaciÃ³n (token JWT)
- âœ… ValidaciÃ³n de datos en backend
- âœ… IA ejecuta localmente (privacidad de datos)
- âœ… No envÃ­a audio a servidores externos
- âœ… Solo texto procesado por Ollama

---

## âš¡ OptimizaciÃ³n

### Modelos Ollama Recomendados:

| Modelo | TamaÃ±o | Velocidad | PrecisiÃ³n | Uso Recomendado |
|--------|--------|-----------|-----------|-----------------|
| `llama3.2` | 2GB | âš¡âš¡âš¡ | â­â­â­ | ProducciÃ³n (rÃ¡pido) |
| `mistral` | 4GB | âš¡âš¡ | â­â­â­â­ | Balanceado |
| `deepseek-r1` | 8GB | âš¡ | â­â­â­â­â­ | MÃ¡xima precisiÃ³n |

**Cambiar modelo:**
```env
# En server/.env
OLLAMA_MODEL=mistral
```

---

## ğŸ“Š Estructura de Datos

### ParsedIncome (Respuesta del sistema):
```typescript
interface ParsedIncome {
  monto: number;              // Valor numÃ©rico del ingreso
  concepto: string;           // DescripciÃ³n breve
  tipo_movimiento: string;    // INGRESO_VENTA | INGRESO_SERVICIO | INGRESO_OTROS
  observaciones?: string;     // Texto original completo
  fecha?: string;             // ISO timestamp
  confidence: number;         // 0-100 (nivel de confianza)
}
```

---

## ğŸ“ Aprendizaje del Modelo

Ollama aprende de los patrones que le das. Puedes mejorar la precisiÃ³n:

1. **Usa vocabulario consistente** en tus comandos
2. **Entrena el modelo** con ejemplos especÃ­ficos de tu negocio
3. **Ajusta el prompt** en `voiceController.js` si necesitas

---

## ğŸš€ Siguiente Nivel

### Ideas para expandir:

1. **Multi-idioma**: Cambiar `language` prop de VoiceRecognition
2. **Comandos complejos**: "Registrar 5 ventas de 20 dÃ³lares cada una"
3. **EdiciÃ³n por voz**: "Modificar el ingreso de ayer a 200 dÃ³lares"
4. **Consultas**: "Â¿CuÃ¡nto vendÃ­ hoy?"
5. **Reportes**: "Genera un reporte de esta semana"

---

## ğŸ“ Soporte

**VerificaciÃ³n de Sistema:**
```bash
# 1. Ollama corriendo
ollama serve

# 2. Modelo descargado
ollama list

# 3. Backend funcionando
curl http://localhost:3000/api/voice/health

# 4. Dependencias instaladas
npm list @react-native-voice/voice expo-linear-gradient
```

---

## ğŸ‰ Â¡Todo Listo!

Ya tienes un sistema completo de reconocimiento de voz con IA local. Solo necesitas:

1. âœ… Instalar dependencias (npm install)
2. âœ… Configurar Ollama (ollama serve)
3. âœ… Agregar rutas al server.js
4. âœ… Usar el componente `VoiceIngresoModal`

**Â¡Disfruta del poder de la IA local en tu aplicaciÃ³n!** ğŸš€ğŸ¤
