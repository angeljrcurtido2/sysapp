# ğŸ¤ GuÃ­a de ImplementaciÃ³n - Reconocimiento de Voz

## âœ… Estado Actual

- âœ… Backend configurado y funcionando
- âœ… Ollama instalado con modelo llama3.2
- âœ… Componentes frontend creados
- âœ… Dependencias instaladas
- âœ… Hook actualizado para usar tu configuraciÃ³n de axios

---

## ğŸš€ CÃ³mo Usar en tu App

### OpciÃ³n 1: Pantalla Completa de DemostraciÃ³n

Ya creÃ© una pantalla de ejemplo en:
```
app/movimiento/ingreso/voz.tsx
```

**Para acceder:**
```tsx
// Navega desde cualquier parte de tu app
import { router } from 'expo-router';

router.push('/movimiento/ingreso/voz');
```

O agrega un botÃ³n en tu menÃº/sidebar:
```tsx
<Pressable onPress={() => router.push('/movimiento/ingreso/voz')}>
  <Text>ğŸ¤ Registro por Voz</Text>
</Pressable>
```

---

### OpciÃ³n 2: Integrar en Pantalla Existente

Puedes agregar el modal de voz a cualquier pantalla:

```tsx
import { useState } from 'react';
import VoiceIngresoModal from '../../../components/VoiceIngresoModal';
import type { ParsedIncome } from '../../../hooks/useVoiceToIncome';

export default function MiPantalla() {
  const [showVoiceModal, setShowVoiceModal] = useState(false);

  const handleIngresoRegistrado = async (ingreso: ParsedIncome) => {
    console.log('ğŸ“Š Datos del ingreso:', ingreso);

    // AquÃ­ puedes guardar el ingreso usando tu API
    // Por ejemplo:
    // await api.post('/ingresos', {
    //   monto: ingreso.monto,
    //   concepto: ingreso.concepto,
    //   tipo: ingreso.tipo_movimiento,
    //   fecha: new Date().toISOString()
    // });
  };

  return (
    <>
      {/* Tu contenido existente */}

      {/* BotÃ³n para abrir reconocimiento de voz */}
      <Pressable onPress={() => setShowVoiceModal(true)}>
        <Text>ğŸ¤ Registrar por Voz</Text>
      </Pressable>

      {/* Modal de voz */}
      <VoiceIngresoModal
        isOpen={showVoiceModal}
        onClose={() => setShowVoiceModal(false)}
        onIngresoRegistrado={handleIngresoRegistrado}
      />
    </>
  );
}
```

---

### OpciÃ³n 3: Solo el Componente de Reconocimiento

Si solo quieres el componente de reconocimiento sin el modal completo:

```tsx
import VoiceRecognition from '../../../components/VoiceRecognition';
import { useVoiceToIncome } from '../../../hooks/useVoiceToIncome';

export default function MiComponente() {
  const { parseVoiceToIncome, isProcessing, error } = useVoiceToIncome();

  const handleVoiceResult = async (text: string) => {
    console.log('ğŸ¤ Texto reconocido:', text);

    const parsedData = await parseVoiceToIncome(text);
    if (parsedData) {
      console.log('âœ… Datos extraÃ­dos:', parsedData);
      // Usar los datos
    }
  };

  return (
    <VoiceRecognition
      onResult={handleVoiceResult}
      onError={(error) => console.error('Error:', error)}
      placeholder="Di algo como: 'Registrar 150 dÃ³lares por venta'"
      enableProcessing={isProcessing}
    />
  );
}
```

---

## ğŸ“± Permisos Requeridos

### Android

AsegÃºrate de tener estos permisos en `android/app/src/main/AndroidManifest.xml`:

```xml
<uses-permission android:name="android.permission.RECORD_AUDIO" />
<uses-permission android:name="android.permission.INTERNET" />
```

### iOS

Agrega esto a `ios/YourApp/Info.plist`:

```xml
<key>NSMicrophoneUsageDescription</key>
<string>Necesitamos acceso al micrÃ³fono para reconocimiento de voz</string>
<key>NSSpeechRecognitionUsageDescription</key>
<string>Necesitamos acceso al reconocimiento de voz para registrar ingresos</string>
```

---

## ğŸ§ª Probar la ImplementaciÃ³n

### 1. AsegÃºrate que el backend estÃ© corriendo

```powershell
# En terminal 1
cd C:\SIS_VENTAS_NEXT\server
npm run dev
```

### 2. Verifica que Ollama estÃ© funcionando

```powershell
# En PowerShell
Invoke-WebRequest https://api.kjhjhkjhkj.shop/api/voice/health
```

### 3. Ejecuta tu app

```bash
# En terminal 2
cd C:\SIS_VENTAS_NEXT\migracion_app_cliente\sysapp
npx expo start
```

### 4. Prueba el reconocimiento de voz

Navega a `/movimiento/ingreso/voz` o usa el componente donde lo agregaste.

---

## ğŸ¯ Ejemplos de Comandos de Voz

Di frases naturales como:

- âœ… "Registrar un ingreso de 150 dÃ³lares por venta de equipos"
- âœ… "Ingreso de 50 pesos por servicio tÃ©cnico"
- âœ… "Anotar 75 dÃ³lares de reparaciÃ³n"
- âœ… "Venta de productos por 200 dÃ³lares"

El sistema extraerÃ¡ automÃ¡ticamente:
```typescript
{
  monto: 150,
  concepto: "Venta de equipos",
  tipo_movimiento: "INGRESO_VENTA",
  confidence: 95,
  fecha: "2025-11-22T00:00:00.000Z"
}
```

---

## ğŸ”§ ConfiguraciÃ³n Avanzada

### Cambiar el idioma

```tsx
<VoiceRecognition
  language="en-US"  // Cambiar a inglÃ©s
  onResult={handleResult}
/>
```

### Personalizar el tÃ­tulo y mensajes

```tsx
<VoiceIngresoModal
  isOpen={showModal}
  onClose={() => setShowModal(false)}
  onIngresoRegistrado={handleIngreso}
  // Puedes extender el componente para aceptar mÃ¡s props
/>
```

---

## ğŸ“Š Estructura de Datos

```typescript
interface ParsedIncome {
  monto: number;              // Valor numÃ©rico
  concepto: string;           // DescripciÃ³n breve
  tipo_movimiento: string;    // INGRESO_VENTA | INGRESO_SERVICIO | INGRESO_OTROS
  observaciones?: string;     // Texto original completo
  fecha?: string;             // ISO timestamp
  confidence: number;         // 0-100 (nivel de confianza)
}
```

---

## ğŸ› Troubleshooting

### Error: "Cannot find module Voice"

```bash
npm install @react-native-voice/voice
npx expo prebuild
```

### Error de permisos de micrÃ³fono

```bash
# Reinstalar la app
npx expo run:android
# o
npx expo run:ios
```

### Backend no responde

Verifica que:
1. El servidor estÃ© corriendo (`npm run dev`)
2. La URL en `axiosConfig.ts` sea correcta
3. Tengas conexiÃ³n a internet (si usas ngrok/cloudflare)

---

## ğŸ¨ Componentes Disponibles

### VoiceRecognition
Componente base de reconocimiento de voz con animaciones.

### VoiceIngresoModal
Modal completo con vista previa de datos y confirmaciÃ³n.

### EjemploVoz
Pantalla completa de ejemplo con historial.

### ModalSuccess
Modal de Ã©xito rediseÃ±ado con animaciones.

---

## âœ… Checklist de ImplementaciÃ³n

- [ ] Backend corriendo en `https://api.kjhjhkjhkj.shop`
- [ ] Ollama funcionando con modelo llama3.2
- [ ] Dependencias instaladas (`@react-native-voice/voice`, `expo-linear-gradient`)
- [ ] Permisos configurados (Android/iOS)
- [ ] Hook `useVoiceToIncome` actualizado con tu axios
- [ ] Componente agregado a tu pantalla
- [ ] Probado en dispositivo/emulador

---

## ğŸš€ Â¡Listo para Usar!

Tu app ahora tiene reconocimiento de voz con IA local.

**Accede a la demo:**
```tsx
router.push('/movimiento/ingreso/voz');
```

**O integra el modal:**
```tsx
<VoiceIngresoModal {...props} />
```

Â¡Disfruta del reconocimiento de voz! ğŸ¤âœ¨
